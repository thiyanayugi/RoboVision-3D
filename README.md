# RoboVision-3D

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![ROS2](https://img.shields.io/badge/ROS2-Humble-blue.svg)](https://docs.ros.org/en/humble/)

**A comprehensive computer vision and robotics system for indoor environment mapping, object detection, and 3D reconstruction.**

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [System Architecture](#system-architecture)
- [Project Modules](#project-modules)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Results](#results)
- [Technical Stack](#technical-stack)
- [Repository Structure](#repository-structure)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

**RoboVision-3D** is an advanced robotics perception system designed for autonomous indoor navigation and environment understanding. The system integrates multiple sensor modalities including stereo vision, LiDAR, and laser scanning to create comprehensive 3D representations of indoor spaces with semantic object understanding.

### Sensor Suite

The system utilizes data from a MESA robot equipped with:

| Sensor                | Purpose                        | Output                     |
| --------------------- | ------------------------------ | -------------------------- |
| **ZED Stereo Camera** | RGB imaging & depth estimation | RGB images, depth maps     |
| **Livox LiDAR**       | High-density 3D scanning       | Point clouds               |
| **2D Laser Scanner**  | Mapping & localization         | Laser scans                |
| **IMU**               | Motion tracking                | Inertial measurements      |
| **Wheel Odometry**    | Pose estimation                | Robot position/orientation |

### Test Environments

- **Bathroom**: Compact indoor space with fixtures
- **Office**: Large workspace with furniture

---

## âœ¨ Features

### ğŸ¯ 3D Object Detection & Localization

- Deep learning-based object detection (YOLOv8)
- 6-DOF pose estimation with oriented bounding boxes
- Multi-sensor fusion (RGB + LiDAR)
- Robust multi-frame clustering

### ğŸŒˆ Point Cloud Colorization

- RGB-LiDAR sensor fusion
- Camera-to-LiDAR projection
- Full environment reconstruction
- Efficient voxel downsampling

### ğŸ—ºï¸ Multi-Survey Map Alignment

- Feature-based map registration
- RANSAC-based robust alignment
- Global optimization with differential evolution
- Sub-pixel accuracy alignment

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RoboVision-3D System                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   RGB-D      â”‚  â”‚    LiDAR     â”‚  â”‚  Laser Scan  â”‚      â”‚
â”‚  â”‚   Camera     â”‚  â”‚   Sensor     â”‚  â”‚   + IMU      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                            â”‚                                  â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                   â”‚  Data Fusion &  â”‚                        â”‚
â”‚                   â”‚ Synchronization â”‚                        â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                            â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚                  â”‚                  â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Object    â”‚  â”‚  Point Cloud    â”‚  â”‚    Map     â”‚     â”‚
â”‚  â”‚  Detection  â”‚  â”‚  Colorization   â”‚  â”‚ Alignment  â”‚     â”‚
â”‚  â”‚  Module     â”‚  â”‚     Module      â”‚  â”‚   Module   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                            â”‚                                  â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                   â”‚  3D Environment â”‚                        â”‚
â”‚                   â”‚  Representation â”‚                        â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Project Modules

### Module 1: Object Detection and Localization

Detect and localize furniture objects in 3D space with accurate oriented bounding boxes.

**Target Objects**: Bathtub, Chair, Couch, Shelf, Table, Toilet

**Key Capabilities:**

- YOLOv8-based 2D detection in RGB images
- LiDAR-based 3D localization
- PCA-based oriented bounding box fitting
- Multi-frame clustering for robustness

**ğŸ“– [Detailed Documentation](module1_object_detection.md)**

---

### Module 2: Point Cloud Colorization

Create photorealistic colored point clouds by fusing RGB camera data with LiDAR scans.

**Key Capabilities:**

- Camera-LiDAR calibration and projection
- Multi-frame point cloud aggregation
- Voxel-based downsampling
- PLY format export

**ğŸ“– [Detailed Documentation](module2_point_cloud.md)**

---

### Module 3: Map Alignment

Align occupancy grid maps from multiple surveys of the same environment.

**Key Capabilities:**

- ORB feature detection and matching
- RANSAC-based robust transformation estimation
- Differential evolution optimization
- Multi-metric alignment scoring

**ğŸ“– [Detailed Documentation](module3_map_alignment.md)**

---

## ğŸš€ Installation

### Prerequisites

- **Python**: 3.10 or higher
- **Git LFS**: For large point cloud files
- **Operating System**: Linux (Ubuntu 20.04+ recommended)

### 1. Clone the Repository

```bash
git clone https://github.com/yugimariraj01/RoboVision-3D.git
cd RoboVision-3D
```

### 2. Install Git LFS

Point cloud files (`.ply`) are stored using Git LFS:

```bash
# Ubuntu/Debian
sudo apt-get install git-lfs

# macOS
brew install git-lfs

# Initialize and pull large files
git lfs install
git lfs pull
```

**Large files managed by LFS:**

- `results/module2/bathroom_colorized.ply` (141 MB, 5.5M points)
- `results/module2/office_colorized.ply` (510 MB, 19.8M points)

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

**Core Dependencies:**

| Package         | Version | Purpose                   |
| --------------- | ------- | ------------------------- |
| `numpy`         | 1.24+   | Numerical computing       |
| `opencv-python` | 4.8+    | Computer vision           |
| `pyyaml`        | -       | Configuration parsing     |
| `scikit-learn`  | -       | Clustering algorithms     |
| `scipy`         | -       | Optimization              |
| `open3d`        | 0.17+   | 3D point cloud processing |
| `ultralytics`   | -       | YOLOv8 detection          |

---

## ğŸ® Quick Start

### Data Preparation (Optional)

The repository includes pre-processed data. To regenerate from ROS bags:

```bash
# Extract sensor data from ROS2 bags
python utils/extract_rosbag_data.py

# Synchronize multi-sensor streams
python utils/synchronize_data.py

# Compute accurate robot poses
python utils/compute_scan_to_map_odom.py

# Run YOLO object detection
python utils/run_yolo_detection.py
```

### Run Module 1: Object Detection

```bash
cd module1_object_detection
python detect_objects.py
python filter_detections.py
python visualize_detections.py
```

**Output:**

- `results/module1/bathroom_detections.json`
- `results/module1/bathroom_detections.png`
- `results/module1/office_detections.json`
- `results/module1/office_detections.png`

### Run Module 2: Point Cloud Colorization

```bash
cd module2_point_cloud
python colorize_clouds.py
```

**Output:**

- `results/module2/bathroom_colorized.ply`
- `results/module2/office_colorized.ply`

### Run Module 3: Map Alignment

```bash
cd module3_map_alignment
python main.py
```

**Output:**

- `results/module3/alignment_transform.yaml`
- `results/module3/aligned_overlay.png`

---

## ğŸ“Š Results

### Object Detection Performance

| Environment | Toilets | Chairs | Couches | Tables | Total  |
| ----------- | ------- | ------ | ------- | ------ | ------ |
| Bathroom    | 1       | 0      | 0       | 0      | **1**  |
| Office      | 0       | 9      | 7       | 3      | **19** |

**Detection Quality:**

- All objects have oriented 3D bounding boxes
- Average confidence: 0.82
- Multi-frame validation (50+ observations per object)

### Point Cloud Statistics

| Environment | Points | File Size | Processing Time |
| ----------- | ------ | --------- | --------------- |
| Bathroom    | 5.5M   | 141 MB    | ~2-3 min        |
| Office      | 19.8M  | 510 MB    | ~10 min         |

### Map Alignment Accuracy

```yaml
Translation: (16.30m, -5.48m)
Rotation: 80.27Â° (1.401 rad)
Scale: 0.9887
Reprojection Error: 1.08 pixels
Edge Alignment: 55.8% within 3px
```

---

## ğŸ› ï¸ Technical Stack

### Computer Vision

- **Object Detection**: YOLOv8 (Ultralytics)
- **Feature Detection**: ORB (OpenCV)
- **Image Processing**: OpenCV 4.8+

### 3D Processing

- **Point Cloud Library**: Open3D
- **Coordinate Transformations**: NumPy + SciPy
- **Voxel Processing**: Open3D VoxelGrid

### Machine Learning

- **Clustering**: DBSCAN (scikit-learn)
- **Optimization**: Differential Evolution (SciPy)
- **Robust Estimation**: RANSAC (OpenCV)

### Robotics

- **Data Format**: ROS2 bags
- **Localization**: Scan-to-map matching
- **Sensor Fusion**: Multi-modal data synchronization

---

## ğŸ“ Repository Structure

```
RoboVision-3D/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ module1_object_detection.md        # Module 1 documentation
â”œâ”€â”€ module2_point_cloud.md             # Module 2 documentation
â”œâ”€â”€ module3_map_alignment.md           # Module 3 documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”‚
â”œâ”€â”€ module1_object_detection/          # Object detection module
â”‚   â”œâ”€â”€ detect_objects.py              # Detection & localization
â”‚   â”œâ”€â”€ filter_detections.py           # False positive filtering
â”‚   â”œâ”€â”€ visualize_detections.py        # Map visualization
â”‚   â”œâ”€â”€ config.yaml                    # Configuration
â”‚   â”œâ”€â”€ detections/                    # YOLO results
â”‚   â””â”€â”€ models/                        # Model weights
â”‚
â”œâ”€â”€ module2_point_cloud/               # Point cloud module
â”‚   â”œâ”€â”€ colorize_clouds.py             # RGB-LiDAR fusion
â”‚   â””â”€â”€ config.yaml                    # Configuration
â”‚
â”œâ”€â”€ module3_map_alignment/             # Map alignment module
â”‚   â”œâ”€â”€ main.py                        # Main pipeline
â”‚   â”œâ”€â”€ map_loader.py                  # Map I/O
â”‚   â”œâ”€â”€ feature_matcher.py             # Feature processing
â”‚   â”œâ”€â”€ aligner.py                     # RANSAC alignment
â”‚   â”œâ”€â”€ optimizer.py                   # Optimization
â”‚   â”œâ”€â”€ visualizer.py                  # Visualization
â”‚   â””â”€â”€ config.yaml                    # Configuration
â”‚
â”œâ”€â”€ utils/                             # Utility scripts
â”‚   â”œâ”€â”€ extract_rosbag_data.py         # ROS2 bag extraction
â”‚   â”œâ”€â”€ synchronize_data.py            # Sensor synchronization
â”‚   â”œâ”€â”€ run_yolo_detection.py          # Batch YOLO inference
â”‚   â””â”€â”€ compute_scan_to_map_odom.py    # Pose estimation
â”‚
â”œâ”€â”€ synchronized_data/                 # Preprocessed data
â”‚   â”œâ”€â”€ bathroom_frames.pkl
â”‚   â”œâ”€â”€ bathroom_metadata.json
â”‚   â”œâ”€â”€ office_frames.pkl
â”‚   â””â”€â”€ office_metadata.json
â”‚
â”œâ”€â”€ scan_to_map_odom/                  # Robot poses
â”‚   â”œâ”€â”€ bathroom_scan_to_map_odom.pkl
â”‚   â””â”€â”€ office_scan_to_map_odom.pkl
â”‚
â”œâ”€â”€ Challenge_Data/                    # Raw input data
â”‚   â”œâ”€â”€ bathroom/
â”‚   â”‚   â”œâ”€â”€ room.pgm                   # Occupancy map
â”‚   â”‚   â”œâ”€â”€ room.yaml                  # Map metadata
â”‚   â”‚   â””â”€â”€ *.db3                      # ROS2 bags
â”‚   â””â”€â”€ office/
â”‚       â”œâ”€â”€ room.pgm
â”‚       â”œâ”€â”€ room.yaml
â”‚       â””â”€â”€ *.db3
â”‚
â””â”€â”€ results/                           # Output results
    â”œâ”€â”€ module1/                       # Detection results
    â”œâ”€â”€ module2/                       # Point clouds
    â””â”€â”€ module3/                       # Aligned maps
```

---

## ğŸ¨ Visualization

### View Point Clouds

```bash
# Using Open3D (Python)
python3 -c "import open3d as o3d; o3d.visualization.draw_geometries([o3d.io.read_point_cloud('results/module2/bathroom_colorized.ply')])"

# Using CloudCompare (recommended)
cloudcompare results/module2/bathroom_colorized.ply
```

### View Detection Results

```bash
# Any image viewer
eog results/module1/bathroom_detections.png
```

### View Map Alignment

```bash
# View aligned maps
eog results/module3/aligned_overlay.png
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Development Setup

```bash
# Clone the repository
git clone https://github.com/yugimariraj01/RoboVision-3D.git
cd RoboVision-3D

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Thiyanayugi Mariraj**

- GitHub: [@yugimariraj01](https://github.com/yugimariraj01)
- Email: thiyanayugi@example.com

---

## ğŸ™ Acknowledgments

- **YOLOv8**: Ultralytics team for the object detection framework
- **Open3D**: Intel ISL for the 3D processing library
- **OpenCV**: OpenCV team for computer vision tools
- **ROS2**: Open Robotics for the robotics middleware

---

## ğŸ“š Citation

If you use this project in your research, please cite:

```bibtex
@software{robovision3d2025,
  author = {Mariraj, Thiyanayugi},
  title = {RoboVision-3D: Computer Vision and Robotics for Indoor Navigation},
  year = {2025},
  url = {https://github.com/yugimariraj01/RoboVision-3D}
}
```

---

<div align="center">
  <strong>Built with â¤ï¸ for autonomous robotics</strong>
</div>
